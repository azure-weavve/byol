"""
Training Summary Generator

í•™ìŠµ ì™„ë£Œ í›„ epochë³„ ì§„í–‰ë„ë¥¼ í…Œì´ë¸”ë¡œ ì •ë¦¬
"""

import json
import os
import pandas as pd
import numpy as np
from pathlib import Path


class TrainingSummary:
    """í•™ìŠµ ì§„í–‰ë„ë¥¼ ì •ë¦¬í•´ì„œ ë³´ì—¬ì£¼ëŠ” í´ë˜ìŠ¤"""
    
    def __init__(self, log_dir='logs', history_file='history.json'):
        """
        Args:
            log_dir: ë¡œê·¸ ë””ë ‰í† ë¦¬
            history_file: history.json íŒŒì¼ëª…
        """
        self.log_dir = log_dir
        self.history_path = os.path.join(log_dir, history_file)
        self.history = None
        
    def load_history(self):
        """history.json ë¡œë“œ"""
        if not os.path.exists(self.history_path):
            print(f"âŒ History file not found: {self.history_path}")
            return False
        
        with open(self.history_path, 'r') as f:
            self.history = json.load(f)
        
        print(f"âœ… History loaded: {len(self.history['epoch'])} epochs")
        return True
    
    def get_checkpoint_summary(self, interval=10):
        """
        Epochë³„ ì§„í–‰ë„ í…Œì´ë¸” ìƒì„± (10 epochë§ˆë‹¤)
        
        âœ… ìˆ˜ì •: evaluation metricsëŠ” ì‹¤ì œ í‰ê°€ëœ epochê³¼ **ê°€ì¥ ê°€ê¹Œìš´** ê°’ì„ ë§¤ì¹­
        ì˜ˆ: epoch 0 â†’ epoch 9ì˜ í‰ê°€ ê²°ê³¼ ì‚¬ìš©
        
        Args:
            interval: ëª‡ epochë§ˆë‹¤ ë³´ì—¬ì¤„ ê²ƒì¸ê°€ (ê¸°ë³¸: 10)
        
        Returns:
            DataFrame
        """
        if self.history is None:
            self.load_history()
        
        epochs = self.history.get('epoch', [])
        train_losses = self.history.get('train_loss', [])
        val_losses = self.history.get('val_loss', [])
        feat_stds = self.history.get('feat_std', [])
        avg_cos_sims = self.history.get('avg_cos_sim', [])
        
        # Clustering metrics (ìˆìœ¼ë©´) - (epoch, value) íŠœí”Œ ë¦¬ìŠ¤íŠ¸
        n_clusters = self.history.get('clustering_n_clusters', [])
        noise_ratio = self.history.get('clustering_noise_ratio', [])
        silhouette = self.history.get('clustering_silhouette', [])
        
        # Rotation invariance (ìˆìœ¼ë©´) - (epoch, value) íŠœí”Œ ë¦¬ìŠ¤íŠ¸
        rotation_inv = self.history.get('rotation_invariance_avg_cosine_similarity', [])
        
        # ğŸ”¹ Helper function: ê°€ì¥ ê°€ê¹Œìš´ evaluation epochì˜ value ì°¾ê¸°
        def find_closest_value(metric_list, target_epoch):
            """
            (epoch, value) íŠœí”Œ ë¦¬ìŠ¤íŠ¸ì—ì„œ target_epochì— **ê°€ì¥ ê°€ê¹Œìš´** evaluation epochì˜ value ì°¾ê¸°
            ì˜ˆ: target=0, metric_list=[(9, 0.6), (19, 0.5)] â†’ 0.6 (epoch 9ê°€ ê°€ì¥ ê°€ê¹Œì›€)
            """
            if not metric_list or len(metric_list) == 0:
                return None
            
            # ëª¨ë“  evaluation epoch ì¶”ì¶œ
            eval_epochs = []
            eval_values = []
            for item in metric_list:
                if isinstance(item, (list, tuple)) and len(item) >= 2:
                    eval_epochs.append(int(item[0]))
                    eval_values.append(item[1])
            
            if len(eval_epochs) == 0:
                return None
            
            # ê°€ì¥ ê°€ê¹Œìš´ evaluation epoch ì°¾ê¸°
            closest_idx = min(range(len(eval_epochs)), 
                            key=lambda i: abs(eval_epochs[i] - target_epoch))
            
            return eval_values[closest_idx]
        
        # Intervalë¡œ ìƒ˜í”Œë§
        summary_data = []
        
        for epoch_idx in range(0, len(epochs), interval):
            if epoch_idx >= len(epochs):
                break
            
            epoch = epochs[epoch_idx]
            
            # ë°ì´í„° ì¶”ì¶œ
            row = {
                'Epoch': int(epoch),
                'Train Loss': f"{train_losses[epoch_idx]:.4f}" if epoch_idx < len(train_losses) else "N/A",
                'Val Loss': f"{val_losses[epoch_idx]:.4f}" if epoch_idx < len(val_losses) else "N/A",
                'Feat Std': f"{feat_stds[epoch_idx]:.4f}" if epoch_idx < len(feat_stds) else "N/A",
                'Avg Cos Sim': f"{avg_cos_sims[epoch_idx]:.4f}" if epoch_idx < len(avg_cos_sims) else "N/A",
            }
            
            # ğŸ”¹ Evaluation metrics: ê°€ì¥ ê°€ê¹Œìš´ í‰ê°€ ê²°ê³¼ ë§¤ì¹­
            sil_value = find_closest_value(silhouette, epoch)
            row['Silhouette'] = f"{sil_value:.4f}" if sil_value is not None else "N/A"
            
            ncl_value = find_closest_value(n_clusters, epoch)
            row['n_clusters'] = int(ncl_value) if ncl_value is not None else "N/A"
            
            noise_value = find_closest_value(noise_ratio, epoch)
            row['Noise %'] = f"{noise_value*100:.1f}%" if noise_value is not None else "N/A"
            
            rot_value = find_closest_value(rotation_inv, epoch)
            row['Rotation Inv'] = f"{rot_value:.4f}" if rot_value is not None else "N/A"
            
            summary_data.append(row)
        
        # ë§ˆì§€ë§‰ epochë„ ì¶”ê°€ (ì™„ë£Œ ìƒíƒœ)
        if len(epochs) > 0 and (len(epochs) - 1) % interval != 0:
            epoch_idx = len(epochs) - 1
            epoch = epochs[epoch_idx]
            
            row = {
                'Epoch': int(epoch),
                'Train Loss': f"{train_losses[epoch_idx]:.4f}" if epoch_idx < len(train_losses) else "N/A",
                'Val Loss': f"{val_losses[epoch_idx]:.4f}" if epoch_idx < len(val_losses) else "N/A",
                'Feat Std': f"{feat_stds[epoch_idx]:.4f}" if epoch_idx < len(feat_stds) else "N/A",
                'Avg Cos Sim': f"{avg_cos_sims[epoch_idx]:.4f}" if epoch_idx < len(avg_cos_sims) else "N/A",
            }
            
            # ğŸ”¹ Evaluation metrics: ê°€ì¥ ê°€ê¹Œìš´ í‰ê°€ ê²°ê³¼ ë§¤ì¹­
            sil_value = find_closest_value(silhouette, epoch)
            row['Silhouette'] = f"{sil_value:.4f}" if sil_value is not None else "N/A"
            
            ncl_value = find_closest_value(n_clusters, epoch)
            row['n_clusters'] = int(ncl_value) if ncl_value is not None else "N/A"
            
            noise_value = find_closest_value(noise_ratio, epoch)
            row['Noise %'] = f"{noise_value*100:.1f}%" if noise_value is not None else "N/A"
            
            rot_value = find_closest_value(rotation_inv, epoch)
            row['Rotation Inv'] = f"{rot_value:.4f}" if rot_value is not None else "N/A"
            
            summary_data.append(row)
        
        return pd.DataFrame(summary_data)
    
    def get_best_epoch_summary(self):
        """
        Best epoch ì •ë³´ ì¶”ì¶œ
        
        Returns:
            dict
        """
        if self.history is None:
            self.load_history()
        
        val_losses = self.history.get('val_loss', [])
        epochs = self.history.get('epoch', [])
        
        if len(val_losses) == 0:
            return None
        
        # Best val loss epoch ì°¾ê¸°
        best_idx = np.argmin(val_losses)
        best_epoch = epochs[best_idx]
        best_val_loss = val_losses[best_idx]
        
        # í•´ë‹¹ epochì˜ ë‹¤ë¥¸ ì§€í‘œë“¤
        train_losses = self.history.get('train_loss', [])
        feat_stds = self.history.get('feat_std', [])
        avg_cos_sims = self.history.get('avg_cos_sim', [])
        silhouette = self.history.get('clustering_silhouette', [])
        
        # ğŸ”¹ Helper function: ê°€ì¥ ê°€ê¹Œìš´ evaluation epoch ì°¾ê¸°
        def find_closest_value(metric_list, target_epoch):
            if not metric_list or len(metric_list) == 0:
                return None
            
            eval_epochs = []
            eval_values = []
            for item in metric_list:
                if isinstance(item, (list, tuple)) and len(item) >= 2:
                    eval_epochs.append(int(item[0]))
                    eval_values.append(item[1])
            
            if len(eval_epochs) == 0:
                return None
            
            closest_idx = min(range(len(eval_epochs)), 
                            key=lambda i: abs(eval_epochs[i] - target_epoch))
            
            return eval_values[closest_idx]
        
        best_info = {
            'Best Epoch': int(best_epoch),
            'Train Loss': f"{train_losses[best_idx]:.4f}" if best_idx < len(train_losses) else "N/A",
            'Val Loss': f"{best_val_loss:.4f}",
            'Feat Std': f"{feat_stds[best_idx]:.4f}" if best_idx < len(feat_stds) else "N/A",
            'Avg Cos Sim': f"{avg_cos_sims[best_idx]:.4f}" if best_idx < len(avg_cos_sims) else "N/A",
        }
        
        # ğŸ”¹ Silhouette: ê°€ì¥ ê°€ê¹Œìš´ í‰ê°€ ê²°ê³¼
        sil_value = find_closest_value(silhouette, best_epoch)
        best_info['Silhouette'] = f"{sil_value:.4f}" if sil_value is not None else "N/A"
        
        return best_info
    
    def print_summary(self, interval=10, save_csv=True):
        """
        ì „ì²´ ìš”ì•½ì„ ì½˜ì†”ì— ì¶œë ¥í•˜ê³  CSV ì €ì¥
        
        Args:
            interval: ëª‡ epochë§ˆë‹¤ ë³´ì—¬ì¤„ ê²ƒì¸ê°€
            save_csv: CSVë¡œ ì €ì¥í•  ê²ƒì¸ê°€
        """
        if self.history is None:
            self.load_history()
        
        print("\n" + "="*120)
        print("ğŸ“Š TRAINING PROGRESS SUMMARY (Every {} Epochs)".format(interval))
        print("="*120)
        
        # Checkpoint summary
        df_checkpoint = self.get_checkpoint_summary(interval=interval)
        print("\n" + df_checkpoint.to_string(index=False))
        
        # Best epoch
        print("\n" + "-"*120)
        print("ğŸ† BEST EPOCH (by Val Loss)")
        print("-"*120)
        
        best_info = self.get_best_epoch_summary()
        if best_info:
            for key, value in best_info.items():
                print(f"{key:20s}: {value}")
        
        # ìµœì¢… ìƒíƒœ
        print("\n" + "-"*120)
        print("âœ… FINAL STATUS")
        print("-"*120)
        
        epochs = self.history.get('epoch', [])
        train_losses = self.history.get('train_loss', [])
        val_losses = self.history.get('val_loss', [])
        feat_stds = self.history.get('feat_std', [])
        silhouette = self.history.get('clustering_silhouette', [])
        
        # ğŸ”¹ Helper function: ê°€ì¥ ê°€ê¹Œìš´ evaluation epoch ì°¾ê¸°
        def find_closest_value(metric_list, target_epoch):
            if not metric_list or len(metric_list) == 0:
                return None
            
            eval_epochs = []
            eval_values = []
            for item in metric_list:
                if isinstance(item, (list, tuple)) and len(item) >= 2:
                    eval_epochs.append(int(item[0]))
                    eval_values.append(item[1])
            
            if len(eval_epochs) == 0:
                return None
            
            closest_idx = min(range(len(eval_epochs)), 
                            key=lambda i: abs(eval_epochs[i] - target_epoch))
            
            return eval_values[closest_idx]
        
        if len(epochs) > 0:
            final_idx = len(epochs) - 1
            final_epoch = epochs[final_idx]
            
            print(f"Total Epochs          : {int(final_epoch) + 1}")
            print(f"Final Train Loss      : {train_losses[final_idx]:.4f}")
            print(f"Final Val Loss        : {val_losses[final_idx]:.4f}")
            print(f"Feature Std           : {feat_stds[final_idx]:.4f}")
            
            # ğŸ”¹ Silhouette: ê°€ì¥ ê°€ê¹Œìš´ í‰ê°€ ê²°ê³¼
            sil_value = find_closest_value(silhouette, final_epoch)
            if sil_value is not None:
                print(f"Silhouette Score      : {sil_value:.4f}", end="")
                if sil_value >= 0.5:
                    print(" âœ… (ëª©í‘œ ë‹¬ì„±!)")
                elif sil_value >= 0.3:
                    print(" â­ (ì–‘í˜¸)")
                else:
                    print(" âš ï¸  (ê°œì„  í•„ìš”)")
        
        print("\n" + "="*120)
        
        # CSV ì €ì¥
        if save_csv:
            csv_path = os.path.join(self.log_dir, 'training_summary.csv')
            df_checkpoint.to_csv(csv_path, index=False)
            print(f"\nğŸ’¾ Summary saved to: {csv_path}")


def generate_training_summary(log_dir='logs', interval=10):
    """
    í•™ìŠµ ì™„ë£Œ í›„ ìš”ì•½ ìƒì„± (í¸ì˜ í•¨ìˆ˜)
    
    Args:
        log_dir: ë¡œê·¸ ë””ë ‰í† ë¦¬
        interval: ëª‡ epochë§ˆë‹¤ ë³´ì—¬ì¤„ ê²ƒì¸ê°€
    """
    summary = TrainingSummary(log_dir=log_dir)
    summary.print_summary(interval=interval, save_csv=True)
    
    return summary


if __name__ == "__main__":
    # í…ŒìŠ¤íŠ¸
    generate_training_summary(log_dir='logs', interval=10)