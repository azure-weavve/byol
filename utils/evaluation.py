"""
Evaluation functions for BYOL wafer pattern clustering

Metrics:
1. Retrieval quality (Precision@k, Recall@k, MRR)
2. Clustering quality (Silhouette, Calinski-Harabasz, Davies-Bouldin)
3. Rotation invariance (D4 group consistency)

PyTorch 1.4.0 compatible
"""

import os
import torch
import numpy as np
import pandas as pd
from sklearn.metrics import silhouette_score, calinski_harabasz_score, davies_bouldin_score
from sklearn.cluster import DBSCAN



def evaluate_knn_consistency(model, dataloader, device, all_features=None,
                              n_samples=500, k=20):
    """
    kNN Consistency í‰ê°€: C4 augmented ë²„ì „ì´ ì›ë³¸ì˜ k-NNì— í¬í•¨ë˜ëŠ” ë¹„ìœ¨

    ì›ë¦¬:
        - Nê°œ ìƒ˜í”Œì— ëŒ€í•´ C4 íšŒì „(90Â°, 180Â°, 270Â°) ì ìš© â†’ ê° embedding ì¶”ì¶œ
        - ì „ì²´ validation set feature poolì—ì„œ ì›ë³¸ì˜ k-NN ê²€ìƒ‰
        - k-NN ì•ˆì— C4 ë³€í™˜ ë²„ì „ì´ í¬í•¨ëœ ë¹„ìœ¨ = consistency

    Args:
        model: BYOL model
        dataloader: validation dataloader
        device: torch device
        all_features: ë¯¸ë¦¬ ì¶”ì¶œí•œ ì „ì²´ feature (Noneì´ë©´ ë‚´ë¶€ì—ì„œ ì¶”ì¶œ)
        n_samples: í‰ê°€ì— ì‚¬ìš©í•  ìƒ˜í”Œ ìˆ˜ (ì „ì²´ì—ì„œ ìƒ˜í”Œë§)
        k: k-NNì˜ k ê°’

    Returns:
        metrics: dict with knn_consistency and details
    """
    model.eval()

    # 1. ì „ì²´ feature pool ì¤€ë¹„ (ì´ë¯¸ ì¶”ì¶œëœ ê²ƒ ì¬í™œìš©)
    if all_features is None:
        from utils.train_byol import extract_features
        all_features, _ = extract_features(model, dataloader, device,
                                            use_target=True, verbose=False)

    # numpyë¡œ ë³€í™˜ (ì´ë¯¸ numpyë©´ ê·¸ëŒ€ë¡œ)
    if isinstance(all_features, torch.Tensor):
        all_features_np = all_features.cpu().numpy()
    else:
        all_features_np = all_features

    N_total = all_features_np.shape[0]

    # 2. í‰ê°€ìš© ìƒ˜í”Œ ì¶”ì¶œ (dataloaderì—ì„œ ì›ë³¸ ì´ë¯¸ì§€ í•„ìš”)
    sample_images = []
    sample_indices = []

    # ëœë¤ ì¸ë±ìŠ¤ ì„ íƒ
    selected_indices = np.random.permutation(N_total)[:n_samples]
    selected_set = set(selected_indices.tolist())

    # dataloaderì—ì„œ í•´ë‹¹ ì¸ë±ìŠ¤ì˜ ì´ë¯¸ì§€ ìˆ˜ì§‘
    current_idx = 0
    for data in dataloader:
        if isinstance(data, (list, tuple)):
            if len(data) == 4:
                images = data[0]
            else:
                images = data[0] if len(data) > 0 else data
        else:
            images = data

        batch_size = images.size(0)
        for i in range(batch_size):
            global_idx = current_idx + i
            if global_idx in selected_set:
                sample_images.append(images[i])
                sample_indices.append(global_idx)

        current_idx += batch_size

        if len(sample_images) >= n_samples:
            break

    actual_n_samples = len(sample_images)
    if actual_n_samples == 0:
        print("âš ï¸  No samples collected for kNN consistency evaluation")
        return {'knn_consistency': 0.0, 'n_samples': 0}

    # 3. ì „ì²´ feature poolì˜ L2 norm ë¯¸ë¦¬ ê³„ì‚° (cosine distanceìš©)
    #    euclidean distance ì‚¬ìš©
    #    sklearn ì—†ì´ ì§ì ‘ ê³„ì‚° (PyTorch 1.4.0 í˜¸í™˜)

    # 4. ê° ìƒ˜í”Œì— ëŒ€í•´ C4 ë³€í™˜ í›„ kNN consistency ê³„ì‚°
    consistencies = []

    with torch.no_grad():
        for idx, (img, global_idx) in enumerate(zip(sample_images, sample_indices)):
            # C4 íšŒì „ ì ìš© (90Â°, 180Â°, 270Â° - 0Â°ëŠ” ì›ë³¸ì´ë¯€ë¡œ ì œì™¸)
            rotated_images = []
            for rot_k in [1, 2, 3]:  # 90Â°, 180Â°, 270Â°
                rotated = torch.rot90(img, k=rot_k, dims=(-2, -1))
                rotated_images.append(rotated)

            # íšŒì „ëœ ì´ë¯¸ì§€ë“¤ì˜ embedding ì¶”ì¶œ
            rotated_batch = torch.stack(rotated_images).to(device)  # (3, C, H, W)
            rotated_embeddings = model.get_embeddings(rotated_batch,
                                                       use_target=True)  # (3, D)
            rotated_embeddings_np = rotated_embeddings.cpu().numpy()

            # ì›ë³¸ feature (ì´ë¯¸ ì¶”ì¶œëœ all_featuresì—ì„œ ê°€ì ¸ì˜´)
            original_feature = all_features_np[global_idx]  # (D,)

            # ì›ë³¸ì˜ k-NN ê²€ìƒ‰ (euclidean distance)
            # all_features_np: (N_total, D), original_feature: (D,)
            diffs = all_features_np - original_feature[np.newaxis, :]  # (N_total, D)
            distances = np.sqrt(np.sum(diffs ** 2, axis=1))  # (N_total,)

            # ìê¸° ìì‹  ì œì™¸í•˜ê³  kê°œ ì„ íƒ
            distances[global_idx] = float('inf')
            knn_indices = np.argpartition(distances, k)[:k]  # top-k ì¸ë±ìŠ¤
            knn_features = all_features_np[knn_indices]  # (k, D)

            # ê° íšŒì „ embeddingì´ k-NN ì•ˆì— ìˆëŠ”ì§€ í™•ì¸
            # "ìˆë‹¤" = k-NN ì¤‘ ê°€ì¥ ê°€ê¹Œìš´ ê²ƒê³¼ì˜ ê±°ë¦¬ê°€ threshold ì´í•˜
            # ëŒ€ì‹  ë” ì§ì ‘ì ì¸ ë°©ë²•: íšŒì „ embeddingê³¼ k-NN featureë“¤ ê°„ ìµœì†Œ ê±°ë¦¬
            # â†’ ì›ë³¸ê³¼ k-NNì˜ ìµœëŒ€ ê±°ë¦¬ë³´ë‹¤ ì‘ìœ¼ë©´ "í¬í•¨"ìœ¼ë¡œ íŒì •
            knn_max_dist = np.max(distances[knn_indices])

            n_found = 0
            for rot_emb in rotated_embeddings_np:
                # íšŒì „ embeddingê³¼ ì „ì²´ feature pool ê°„ ê±°ë¦¬
                rot_diffs = all_features_np - rot_emb[np.newaxis, :]
                rot_distances = np.sqrt(np.sum(rot_diffs ** 2, axis=1))

                # ì´ íšŒì „ embeddingì˜ ê°€ì¥ ê°€ê¹Œìš´ ì´ì›ƒì´ ì›ë³¸ì˜ k-NN ì•ˆì— ìˆëŠ”ê°€?
                # ë˜ëŠ” ë” ì§ì ‘ì ìœ¼ë¡œ: ì´ íšŒì „ embeddingì´ ì›ë³¸ì˜ k-NN ë°˜ê²½ ì•ˆì— ìˆëŠ”ê°€?
                rot_dist_to_original = np.sqrt(np.sum((rot_emb - original_feature) ** 2))
                if rot_dist_to_original <= knn_max_dist:
                    n_found += 1

            consistency = n_found / 3.0  # C4ì—ì„œ ì›ë³¸ ì œì™¸ 3ê°œ
            consistencies.append(consistency)

            if (idx + 1) % 100 == 0:
                print(f"  kNN Consistency: {idx+1}/{actual_n_samples} samples processed, "
                      f"running avg: {np.mean(consistencies):.4f}")

    avg_consistency = np.mean(consistencies)
    std_consistency = np.std(consistencies)

    metrics = {
        'knn_consistency': avg_consistency,
        'knn_consistency_std': std_consistency,
        'n_samples': actual_n_samples,
        'k': k,
        'perfect_consistency_ratio': np.mean([c == 1.0 for c in consistencies]),
        'zero_consistency_ratio': np.mean([c == 0.0 for c in consistencies]),
    }

    print(f"\n  kNN Consistency: {avg_consistency:.4f} (Â±{std_consistency:.4f})")
    print(f"  Perfect (3/3): {metrics['perfect_consistency_ratio']:.1%}")
    print(f"  Zero (0/3): {metrics['zero_consistency_ratio']:.1%}")

    return metrics


def compute_pairwise_distances(features, metric='euclidean'):
    """
    Compute pairwise distances

    Args:
        features: (N, D) feature tensor
        metric: 'euclidean' or 'cosine'

    Returns:
        distances: (N, N) distance matrix
    """
    if metric == 'euclidean':
        # Euclidean distance
        # ||a - b||^2 = ||a||^2 + ||b||^2 - 2*a^T*b
        features_squared = (features ** 2).sum(dim=1, keepdim=True)
        distances = features_squared + features_squared.t() - 2 * torch.mm(features, features.t())
        distances = torch.sqrt(torch.clamp(distances, min=0.0))

    elif metric == 'cosine':
        # Cosine distance = 1 - cosine similarity
        features_norm = features / (features.norm(dim=1, keepdim=True) + 1e-8)
        cosine_sim = torch.mm(features_norm, features_norm.t())
        distances = 1 - cosine_sim

    else:
        raise ValueError(f"Invalid metric: {metric}")

    return distances


def evaluate_retrieval(features, k=5, metric='euclidean', ground_truth_func=None):
    """
    Evaluate retrieval quality

    Args:
        features: (N, D) feature tensor
        k: number of nearest neighbors
        metric: distance metric
        ground_truth_func: function to determine if two samples are similar
                          (optional, for synthetic evaluation)

    Returns:
        metrics: dict with Precision@k, Recall@k, MRR
    """
    N = features.size(0)

    # Compute distances
    distances = compute_pairwise_distances(features, metric=metric)

    # Get k nearest neighbors for each sample (excluding self)
    # Sort by distance
    sorted_indices = torch.argsort(distances, dim=1)

    # Exclude self (first element is always self with distance 0)
    nearest_neighbors = sorted_indices[:, 1:k+1]

    # If ground truth function is provided, compute precision/recall
    if ground_truth_func is not None:
        precisions = []
        recalls = []
        reciprocal_ranks = []

        for i in range(N):
            # Get ground truth similar samples
            gt_similar = ground_truth_func(i)

            if len(gt_similar) == 0:
                continue

            # Top-k predictions
            top_k = nearest_neighbors[i].cpu().numpy()

            # True positives
            tp = len(set(top_k) & set(gt_similar))

            # Precision@k
            precision = tp / k
            precisions.append(precision)

            # Recall@k
            recall = tp / len(gt_similar)
            recalls.append(recall)

            # MRR (Mean Reciprocal Rank)
            rank = None
            for r, idx in enumerate(top_k):
                if idx in gt_similar:
                    rank = r + 1
                    break
            if rank is not None:
                reciprocal_ranks.append(1.0 / rank)
            else:
                reciprocal_ranks.append(0.0)

        metrics = {
            'precision_at_k': np.mean(precisions),
            'recall_at_k': np.mean(recalls),
            'mrr': np.mean(reciprocal_ranks)
        }

    else:
        # Without ground truth, just return average distances
        avg_distances = []
        for i in range(N):
            top_k = nearest_neighbors[i]
            avg_dist = distances[i, top_k].mean().item()
            avg_distances.append(avg_dist)

        metrics = {
            'avg_distance_top_k': np.mean(avg_distances),
            'std_distance_top_k': np.std(avg_distances)
        }

    return metrics


def estimate_optimal_eps(features, min_samples=10, method='elbow'):
    """
    K-distance graph ê¸°ë°˜ ìµœì  eps ì¶”ì •
    ë‹¹ì‹ ì˜ latent spaceì— ë§ì¶¤í˜•
    
    Args:
        features: (N, D) embeddings
        min_samples: DBSCAN min_samples
        method: 'elbow' or 'percentile'
    
    Returns:
        eps: ì¶”ì •ëœ eps ê°’
    """
    from sklearn.neighbors import NearestNeighbors
    import numpy as np
    
    # K-distance graph ìƒì„±
    neighbors = NearestNeighbors(n_neighbors=min_samples)
    neighbors_fit = neighbors.fit(features)
    distances, indices = neighbors_fit.kneighbors(features)
    
    # min_samplesë²ˆì§¸ ê±°ë¦¬ ì¶”ì¶œ ë° ì •ë ¬
    k_distances = np.sort(distances[:, min_samples-1], axis=0)
    
    if method == 'elbow':
        # Elbow point ì°¾ê¸° (2ì°¨ ë¯¸ë¶„)
        second_derivative = np.diff(k_distances, n=2)
        elbow_idx = np.argmax(second_derivative)
        eps = k_distances[elbow_idx]
        
    elif method == 'percentile':
        # Percentile ê¸°ë°˜ (ë” ë³´ìˆ˜ì , ê¶Œì¥)
        # 90 percentile = ëŒ€ë¶€ë¶„ì˜ ì ì„ í¬í•¨í•˜ë˜ sparse ì œê±°
        eps = np.percentile(k_distances, 70)
    
    return eps, k_distances


def visualize_k_distance_graph(features, min_samples=10, save_path=None):
    """
    K-distance graph ì‹œê°í™” (eps ì„ íƒ ë„ì›€)
    """
    import matplotlib.pyplot as plt
    plt.rcParams['font.family'] = 'NanumGothic'
    plt.rcParams['axes.unicode_minus'] = False
    
    eps, k_distances = estimate_optimal_eps(features, min_samples, method='elbow')
    
    fig, ax = plt.subplots(figsize=(12, 5))
    
    ax.plot(k_distances, linewidth=1)
    ax.axhline(y=eps, color='r', linestyle='--', label=f'Estimated eps={eps:.4f}')
    ax.set_xlabel('Data Points (sorted)')
    ax.set_ylabel('K-distance')
    ax.set_title('K-distance Graph for DBSCAN eps Selection')
    ax.legend()
    ax.grid(True, alpha=0.3)
    
    if save_path:
        plt.savefig(save_path, dpi=150, bbox_inches='tight')
        print(f"K-distance graph saved to {save_path}")
    
    plt.close()
    
    return eps


def evaluate_clustering(features, min_cluster_size=50, min_samples=10):
    """
    DBSCAN with optimal eps estimation
    
    Args:
        features: (N, D) embeddings
        min_cluster_size: minimum cluster size (HDBSCAN í˜¸í™˜)
        min_samples: DBSCAN min_samples
    
    Returns:
        metrics: dict (í•­ìƒ ìœ íš¨í•œ ê°’ ë°˜í™˜ ë³´ì¥)
        labels: cluster labels
    """
    import numpy as np
    from sklearn.cluster import DBSCAN
    from sklearn.metrics import silhouette_score, calinski_harabasz_score, davies_bouldin_score
    import torch
    
    # Convert to numpy
    if isinstance(features, torch.Tensor):
        features = features.cpu().numpy()

    # âœ… k-distance ê³„ì‚°
    from sklearn.neighbors import NearestNeighbors
    neighbors = NearestNeighbors(n_neighbors=min_samples)
    neighbors.fit(features)
    distances, _ = neighbors.kneighbors(features)
    k_distances = np.sort(distances[:, min_samples-1])
    
    # âœ… eps í›„ë³´ ìƒì„± (ë” ë„“ì€ ë²”ìœ„)
    percentile_candidates = [30, 40, 50, 60, 70, 80, 90]
    eps_candidates = [np.percentile(k_distances, p) for p in percentile_candidates]
    
    print("\nğŸ” Testing multiple eps values:")
    print("â”€" * 80)
    
    all_results = []  # ëª¨ë“  ê²°ê³¼ ì €ì¥
    
    for percentile, eps in zip(percentile_candidates, eps_candidates):
        labels = DBSCAN(eps=eps, min_samples=min_samples).fit_predict(features)
        
        n_clusters = len(np.unique(labels[labels != -1]))
        noise_ratio = (labels == -1).sum() / len(labels)
        non_noise_count = (labels != -1).sum()
        
        # Silhouette ê³„ì‚° (ê°€ëŠ¥í•œ ê²½ìš°)
        sil = None
        if n_clusters >= 2 and non_noise_count >= 10:
            try:
                non_noise = labels[labels != -1]
                clustered_features = features[labels != -1]
                sil = silhouette_score(clustered_features, non_noise)
            except:
                sil = None
        
        # Score ê³„ì‚°
        if sil is not None:
            # ëª©í‘œ: n_clusters 15-40, noise < 15%, silhouette > 0.5
            score = sil - 0.1 * abs(n_clusters - 25) / 25 - 0.3 * noise_ratio
        elif n_clusters >= 2:
            # silhouette ì—†ìœ¼ë©´ í´ëŸ¬ìŠ¤í„° ìˆ˜ì™€ noiseë§Œ ê³ ë ¤
            score = -abs(n_clusters - 25) / 25 - noise_ratio
        else:
            score = -999  # í´ëŸ¬ìŠ¤í„°ê°€ 1ê°œ ì´í•˜ë©´ ìµœì•…
        
        all_results.append({
            'percentile': percentile,
            'eps': eps,
            'labels': labels,
            'n_clusters': n_clusters,
            'noise_ratio': noise_ratio,
            'silhouette': sil,
            'score': score
        })
        
        # ì¶œë ¥
        sil_str = f"{sil:.4f}" if sil is not None else "N/A"
        print(f"percentile={percentile:2d}: eps={eps:.4f}, "
              f"clusters={n_clusters:2d}, noise={noise_ratio:5.1%}, "
              f"silhouette={sil_str}, score={score:7.4f}")
    
    print("â”€" * 80)
    
    # âœ… ìµœì„ ì˜ ê²°ê³¼ ì„ íƒ (score ê¸°ì¤€)
    all_results.sort(key=lambda x: x['score'], reverse=True)
    best = all_results[0]
    
    # âœ… ê²°ê³¼ê°€ ë„ˆë¬´ ì•ˆ ì¢‹ìœ¼ë©´ ê²½ê³ 
    if best['n_clusters'] < 2:
        print("âš ï¸  WARNING: Could not find 2+ clusters!")
        print("    This might indicate:")
        print("    1. Model not trained enough (features too similar)")
        print("    2. Need to adjust min_samples or eps range")
        print("    3. Data might have very few distinct patterns")
    
    print(f"\nâœ… Selected: eps={best['eps']:.4f}, clusters={best['n_clusters']}, "
          f"noise={best['noise_ratio']:.1%}, silhouette={best['silhouette']}")
    
    labels = best['labels']
    
    # âœ… Metrics ê³„ì‚° (í•­ìƒ ë°˜í™˜ ë³´ì¥)
    non_noise_mask = labels != -1
    n_clusters = len(np.unique(labels[non_noise_mask]))
    noise_ratio = (labels == -1).sum() / len(labels)
    
    # Clustering quality metrics
    if n_clusters >= 2 and non_noise_mask.sum() >= 10:
        clustered_features = features[non_noise_mask]
        clustered_labels = labels[non_noise_mask]
        
        try:
            silhouette = silhouette_score(clustered_features, clustered_labels)
            calinski = calinski_harabasz_score(clustered_features, clustered_labels)
            davies = davies_bouldin_score(clustered_features, clustered_labels)
        except:
            silhouette = None
            calinski = None
            davies = None
    else:
        silhouette = None
        calinski = None
        davies = None
    
    metrics = {
        'n_clusters': n_clusters,
        'noise_ratio': noise_ratio,
        'silhouette': silhouette,
        'calinski_harabasz': calinski,
        'davies_bouldin': davies
    }

    return metrics, labels


def evaluate_rotation_invariance(model, test_samples, device, metric='cosine'):
    """
    Evaluate D4 rotation invariance

    Args:
        model: BYOL model
        test_samples: (N, 1, H, W) test samples
        device: torch device
        metric: distance metric

    Returns:
        metrics: dict with invariance metrics
    """
    from utils.augmentation import D4Transform

    model.eval()

    all_cos_sims = []
    all_variances = []

    with torch.no_grad():
        for i in range(test_samples.size(0)):
            sample = test_samples[i]  # (1, H, W)

            # Get all 8 D4 transformations -> C4
            # d4_transforms = D4Transform.get_all_transforms(sample)
            # d4_batch = torch.stack(d4_transforms).to(device)  # (8, 1, H, W)
            c4_transforms = D4Transform.get_c4_transforms(sample)
            c4_batch = torch.stack(c4_transforms).to(device)  # (4, C, H, W)

            # Extract embeddings
            # embeddings = model.get_embeddings(d4_batch, use_target=True)  # (8, D)
            embeddings = model.get_embeddings(c4_batch, use_target=True)  # (4, D)

            # Compute pairwise cosine similarities within D4 group
            embeddings_norm = embeddings / (embeddings.norm(dim=1, keepdim=True) + 1e-8)
            cos_sim_matrix = torch.mm(embeddings_norm, embeddings_norm.t())

            # Average cosine similarity (excluding diagonal)
            # mask = ~torch.eye(8, dtype=torch.bool, device=device)
            mask = ~torch.eye(4, dtype=torch.bool, device=device)
            avg_cos_sim = cos_sim_matrix[mask].mean().item()
            all_cos_sims.append(avg_cos_sim)

            # Variance of embeddings (lower is better for invariance)
            variance = embeddings.var(dim=0).mean().item()
            all_variances.append(variance)

    metrics = {
        'avg_cosine_similarity': np.mean(all_cos_sims),
        'std_cosine_similarity': np.std(all_cos_sims),
        'avg_variance': np.mean(all_variances),
        'std_variance': np.std(all_variances),
        'min_cosine_similarity': np.min(all_cos_sims),
        'max_cosine_similarity': np.max(all_cos_sims)
    }

    return metrics


def evaluate_cluster_consistency_d4(model, test_samples, device, min_cluster_size=5):
    """
    Evaluate if D4 transformations are assigned to the same cluster

    Args:
        model: BYOL model
        test_samples: (N, 1, H, W) test samples
        device: torch device
        min_cluster_size: minimum cluster size for HDBSCAN

    Returns:
        consistency_ratio: ratio of D4 groups in same cluster
    """
    from utils.augmentation import D4Transform

    model.eval()

    all_embeddings = []
    group_ids = []

    with torch.no_grad():
        for i in range(test_samples.size(0)):
            sample = test_samples[i]

            # Get all 8 D4 transformations
            d4_transforms = D4Transform.get_all_transforms(sample)
            d4_batch = torch.stack(d4_transforms).to(device)

            # Extract embeddings
            embeddings = model.get_embeddings(d4_batch, use_target=True)

            all_embeddings.append(embeddings.cpu())
            # group_ids.extend([i] * 8)  # Group ID for each transformation (D4)
            group_ids.extend([i] * 4)  # Group ID for each transformation (C4)

    # Concatenate all embeddings
    all_embeddings = torch.cat(all_embeddings, dim=0)  # (N*8, D)

    # Cluster
    _, cluster_labels = evaluate_clustering(
        all_embeddings,
        min_cluster_size=min_cluster_size
    )

    # Check consistency: how many D4 groups are in the same cluster?
    n_samples = test_samples.size(0)
    consistent_groups = 0

    for i in range(n_samples):
        # Get cluster labels for this D4 group
        # group_labels = cluster_labels[i*8:(i+1)*8] # D4
        group_labels = cluster_labels[i*4:(i+1)*4] # C4

        # Check if all in same cluster (and not noise)
        unique_labels = np.unique(group_labels)
        if len(unique_labels) == 1 and unique_labels[0] != -1:
            consistent_groups += 1

    consistency_ratio = consistent_groups / n_samples

    return consistency_ratio


def evaluate_all(model, dataloader, device, n_samples_invariance=100, n_samples_knn=500, k_knn=20, log_dir='logs'):
    """
    Comprehensive evaluation with DBSCAN optimization
    ë³€ê²½ì‚¬í•­:
    - knn_consistency í‰ê°€ ì¶”ê°€
    - rotation_invarianceëŠ” ìœ ì§€ (ëª¨ë‹ˆí„°ë§ìš©, composite scoreì—ì„œë§Œ ì œì™¸)
    """
    from utils.train_byol import extract_features
    import os

    print("Extracting features...")
    features, _ = extract_features(model, dataloader, device, use_target=True, verbose=False)

    print("\nEvaluating retrieval...")
    retrieval_metrics = evaluate_retrieval(features, k=5, metric='euclidean')

    # K-distance graph ì‹œê°í™” (eps ì„ íƒ ë„ì›€)
    print("\nVisualizing k-distance graph...")
    visualize_k_distance_graph(
        features, 
        min_samples=10,
        save_path=os.path.join(log_dir, 'k_distance_graph.png')
    )

    print("\nEvaluating clustering...")
    clustering_metrics, labels = evaluate_clustering(features, min_cluster_size=50)

    # Get test samples for rotation invariance
    # ===== ê¸°ì¡´ rotation invariance (ëª¨ë‹ˆí„°ë§ìš© ìœ ì§€) =====
    print("\nEvaluating rotation invariance...")
    test_samples = []
    for data in dataloader:
        if isinstance(data, (list, tuple)):
            images = data[0]
        else:
            images = data

        test_samples.append(images)

        if len(test_samples) * images.size(0) >= n_samples_invariance:
            break

    test_samples = torch.cat(test_samples, dim=0)[:n_samples_invariance]

    invariance_metrics = evaluate_rotation_invariance(model, test_samples, device)
    consistency_ratio = evaluate_cluster_consistency_d4(model, test_samples, device)

    # ===== ğŸ†• kNN Consistency ì¶”ê°€ =====
    print("\nEvaluating kNN consistency...")
    knn_metrics = evaluate_knn_consistency(
        model, dataloader, device,
        all_features=features,
        n_samples=n_samples_knn,
        k=k_knn
    )

    # Combine all metrics
    all_metrics = {
        'retrieval': retrieval_metrics,
        'clustering': clustering_metrics,
        'rotation_invariance': invariance_metrics,
        'cluster_consistency_d4': consistency_ratio,
        'knn_consistency': knn_metrics,  # ğŸ†•
    }

    return all_metrics, labels

# evaluation.pyì— ì¶”ê°€
def find_optimal_dbscan_params(features, min_samples_list=[5, 10, 15], 
                                percentiles=[75, 80, 85, 90, 95]):
    """
    ì—¬ëŸ¬ íŒŒë¼ë¯¸í„° ì¡°í•© í…ŒìŠ¤íŠ¸
    """
    results = []
    
    for min_samples in min_samples_list:
        for percentile in percentiles:
            eps, _ = estimate_optimal_eps(features, min_samples, method='percentile')
            # ìˆ˜ë™ìœ¼ë¡œ percentile ì ìš©
            from sklearn.neighbors import NearestNeighbors
            neighbors = NearestNeighbors(n_neighbors=min_samples)
            neighbors_fit = neighbors.fit(features)
            distances, _ = neighbors_fit.kneighbors(features)
            k_distances = np.sort(distances[:, min_samples-1], axis=0)
            eps = np.percentile(k_distances, percentile)
            
            # í‰ê°€
            from sklearn.cluster import DBSCAN
            labels = DBSCAN(eps=eps, min_samples=min_samples).fit_predict(features)
            
            n_clusters = len(np.unique(labels[labels != -1]))
            noise_ratio = (labels == -1).sum() / len(labels)
            
            if n_clusters > 1 and (labels != -1).sum() > 10:
                non_noise = labels[labels != -1]
                clustered_features = features[labels != -1]
                from sklearn.metrics import silhouette_score
                silhouette = silhouette_score(clustered_features, non_noise)
            else:
                silhouette = None
            
            results.append({
                'min_samples': min_samples,
                'percentile': percentile,
                'eps': eps,
                'n_clusters': n_clusters,
                'noise_ratio': noise_ratio,
                'silhouette': silhouette
            })
    
    return pd.DataFrame(results)

# ì‚¬ìš© (epoch 0ì— í•œ ë²ˆë§Œ)
# tuning_results = find_optimal_dbscan_params(features)
# print(tuning_results.to_string())
# ê°€ì¥ ì¢‹ì€ ì¡°í•© ì„ íƒí•´ì„œ íŒŒë¼ë¯¸í„° ê³ ì •


def print_evaluation_results(metrics):
    """
    Print evaluation results in a nice format

    Args:
        metrics: dict from evaluate_all
    """
    print("\n" + "="*60)
    print("EVALUATION RESULTS")
    print("="*60)

    # Retrieval
    print("\nRetrieval Metrics:")
    print("-" * 60)
    for key, value in metrics['retrieval'].items():
        if value is not None:
            print(f"  {key:30s}: {value:.4f}")

    # Clustering
    print("\nClustering Metrics:")
    print("-" * 60)
    for key, value in metrics['clustering'].items():
        if value is not None:
            if isinstance(value, float):
                print(f"  {key:30s}: {value:.4f}")
            else:
                print(f"  {key:30s}: {value}")

    # Rotation Invariance
    print("\nRotation Invariance Metrics:")
    print("-" * 60)
    for key, value in metrics['rotation_invariance'].items():
        print(f"  {key:30s}: {value:.4f}")

    print(f"\n  {'Cluster Consistency (D4)':30s}: {metrics['cluster_consistency_d4']:.4f}")

    print("\n" + "="*60)


def test_evaluation():
    """Test evaluation functions"""
    print("Testing evaluation functions...")

    # Create dummy features
    N = 100
    D = 512
    features = torch.randn(N, D)

    # Test retrieval
    print("\nTesting retrieval evaluation...")
    retrieval_metrics = evaluate_retrieval(features, k=5)
    print(f"Retrieval metrics: {retrieval_metrics}")

    # Test clustering
    print("\nTesting clustering evaluation...")
    clustering_metrics, labels = evaluate_clustering(features, min_cluster_size=10)
    print(f"Clustering metrics: {clustering_metrics}")
    print(f"Unique labels: {np.unique(labels)}")

    print("\nEvaluation test passed!")


if __name__ == "__main__":
    test_evaluation()